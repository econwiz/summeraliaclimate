{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a2629-83a4-49fb-a223-89d2992a2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xagg as xa\n",
    "import geopandas as gpd \n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c0b4f5-7927-43ab-b92e-48d25f85c38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stata_path = \"/shared/share_hle/data/aux_data/global_mortality_panel_public.dta\"\n",
    "\n",
    "panel_df, meta = pyreadstat.read_dta(stata_path)\n",
    "\n",
    "years = sorted(panel_df[\"year\"].unique())\n",
    "\n",
    "years_list = sorted(panel_df[\"year\"].dropna().astype(int).unique().tolist())\n",
    "\n",
    "print(years_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e99d93-3add-41d5-a405-9f19e0c16985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_paths = pd.read_csv(\"car_paths.csv\", dtype=str)\n",
    "\n",
    "df_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51263571-15ea-4f55-ad3c-6a811a1ceaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_paths.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0421e69-d916-418a-a53d-011012788107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape_path = \"/shared/share_hle/data/aux_data/geo_data/impact-region.shp\"\n",
    "\n",
    "gdf = gpd.read_file(shape_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6140dfb-6f49-455b-8a47-ce08b7426751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = ds.assign(T1 = ds.tas, T2 = ds.tas**2, T3 = ds.tas**3,T4 = ds.tas**4)\n",
    "\n",
    "# 4) Sum over days and take the mean\n",
    "T1_sum = ds.T1.sum(\"time\")\n",
    "T2_sum = ds.T2.sum(\"time\")\n",
    "T3_sum = ds.T3.sum(\"time\")\n",
    "T4_sum = ds.T4.sum(\"time\")\n",
    "Tmean  = ds.tas.mean(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a110a8-9e36-4b6c-9816-cd2ada1c3a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_climate(ds_path):\n",
    "    if ds_path.endswith(\".zarr\"):\n",
    "        return xr.open_zarr(ds_path, consolidated=False)\n",
    "    else:\n",
    "        return xr.open_dataset(ds_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee32187-cbcc-47b1-86b4-5e235251bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "xa.set_options(impl=\"numba\", silent=True)\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "years = years_list\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ds = open_climate(row['filepath'])\n",
    "    \n",
    "    product = row[\"product\"]\n",
    "    path     = row[\"filepath\"]\n",
    "    print(f\"Processing {product}\")\n",
    "    \n",
    "    ds_all = open_climate(path).chunk({\"time\": 30})\n",
    "    ds_grid = ds_all.isel(time=0, drop=True)\n",
    "    wm      = xa.pixel_overlaps(ds_grid, gdf)\n",
    "    \n",
    "    for yr in years:\n",
    "        print(f\"  Year {yr}\")\n",
    "        ds_yr = ds_all.sel(time=slice(f\"{yr}-01-01\", f\"{yr}-12-31\"))\n",
    "\n",
    "        ds_poly = xr.Dataset({\n",
    "            \"T1_sum\": (ds_yr.tas**1).sum(\"time\"),\n",
    "            \"T2_sum\": (ds_yr.tas**2).sum(\"time\"),\n",
    "            \"T3_sum\": (ds_yr.tas**3).sum(\"time\"),\n",
    "            \"T4_sum\": (ds_yr.tas**4).sum(\"time\"),\n",
    "            \"Tmean\" :  ds_yr.tas.mean(\"time\"),\n",
    "        })\n",
    "\n",
    "        agg    = xa.aggregate(ds_poly, wm)\n",
    "        df_reg = agg.to_dataframe().reset_index()\n",
    "\n",
    "        df_reg[\"product\"] = product\n",
    "        df_reg[\"year\"]    = yr\n",
    "\n",
    "        all_rows.append(df_reg)\n",
    "\n",
    "big = pd.concat(all_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca7042-6fbc-4245-aa3b-1a5a9f585978",
   "metadata": {},
   "outputs": [],
   "source": [
    "big = big.rename(columns={\"region_id\": \"region\"})\n",
    "if \"time\" in big.columns:\n",
    "    big = big.drop(columns=\"time\")\n",
    "\n",
    "cols = [\"product\", \"region\", \"year\"] + [c for c in big.columns if c not in (\"product\",\"region\",\"year\")]\n",
    "big  = big[cols]\n",
    "\n",
    "out_path = \"/mnt/data/all_products_by_region_year.dta\"\n",
    "big.to_stata(out_path, write_index=False, version=118)\n",
    "print(f\"Wrote {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hle_iv)",
   "language": "python",
   "name": "hle_iv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
